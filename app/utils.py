import configparser
import requests
import datetime
import base64
import os
import random
import time
import random
import sys
import logging

from datetime import datetime
from zoneinfo import ZoneInfo
from bs4 import BeautifulSoup

from pathlib import Path
from openai import OpenAI

sys.path.append(os.path.join(os.path.dirname(sys.path[0])))
import app.config as cfg



timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

openai_client = OpenAI(api_key=cfg.openai_token)






def get_log(name: str = __name__, log_file: str = cfg.logpath) -> logging.Logger:
    """
    Returns a logger that logs to console and a file, without duplicating messages.
    """
    if os.path.isdir(log_file):
        log_file = f"{log_file}/linkendinbot.log"

    logger = logging.getLogger(name)
    logger.setLevel(cfg.loglevel)

    if not logger.hasHandlers():
        # --- Console handler ---
        ch = logging.StreamHandler(sys.stdout)
        ch.setLevel(cfg.loglevel)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        ch.setFormatter(formatter)
        logger.addHandler(ch)

        # --- File handler ---
        # Ensure log directory exists
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        
        fh = logging.FileHandler(log_file)
        fh.setLevel(cfg.loglevel)
        fh.setFormatter(formatter)
        logger.addHandler(fh)

    # Prevent propagation to root logger
    logger.propagate = False

    return logger


log = get_log(os.path.basename(__file__))



def get_dry_run():
    if cfg.dry_run is False:
        return False
    else:
        log.warning(f"Dry Run set {cfg.dry_run}. Saving posts locally only. No automated posting.")
        return True
    




def random_text_prompt():
    if not cfg.text_prompt_file:
        return cfg.text_prompt
    else:
        with open(f"{os.getcwd()}/config/{cfg.text_prompt_file}", "r", encoding="utf-8") as f:
            rline = None
            for i, line in enumerate(f, 1):
                if random.randrange(i) == 0:  # Wahrscheinlichkeit 1/i
                    rline = line.strip()
    return rline

    



def create_and_save_post(prompt=None):
    """
    Generate new content as html file.
    optional parameter: a prompt for the Text generator. 
    If no prompt is give, one will be random selceted from the Promptsfile (see config)
    """
    try:
        if not prompt:
            prompt = random_text_prompt()
            log.info("Generate new content with random prompt")
        status, text = generate_text(prompt)    

        if not status:
            log.warning("Text generation failed - aborting!")
            return False, None
    except Exception as e:
        log.error(f"No Text generated by AI - Aborting \n {e}")
        return False, None
        
    if cfg.demo:
        log.warning(f"Demo-Mode is {cfg.demo}")
        image = "https://picsum.photos/200/300"
    else:
        image = generate_image(text)        # returns the filename only
        if not image:
            image = "https://picsum.photos/200/300"
        else:
            image = f"/content/images/{image}"  # adding the relative path for the html file 

    html_file = save_post_as_html(text, image)
    fqdp = Path(html_file)
    log.info(f"New Post saved as {fqdp}")
    return True, html_file




def generate_text(prompt=None):
    log.info(f"AI in use for text: {cfg.text_ai}")
 
    if not prompt:
        log.info("select random prompt to generate Text")
        prompt = random_text_prompt()
    
    if (cfg.text_ai == "claude"):
        text = generate_text_with_claude(prompt)

    else:
        text = generate_text_with_chatgpt(prompt)
        ok = check_text_with_chatgpt(text)
        attempts = 0
        while not ok:
            attempts += 1
            if attempts <= 3:
                log.warning(f"Genrated Text is not useable for LinkedIn. Try to find something better ({attempts}. of 3 attempts)...")
                improve_prompt = f"{cfg.improve_prompt} {text}"
                text = generate_text_with_chatgpt(improve_prompt)
                ok = check_text_with_chatgpt(text)
            else:
                log.info(f"The following prompt is not useable for LinkedIn Text Generation. Improve the prompt before trying the next time: \n{prompt}\n\n")
                log.warning("Aborting Text generation after 3 attemtps")
                return False, "The given prompt is not useable for LinkedIn"
    return True, text



# --- Claude Textgenerierung ---
def generate_text_with_claude(text_prompt):
    log.debug("Erzeuge Text mit Claude AI...")

    url = "https://api.anthropic.com/v1/messages"
    headers = {
        "x-api-key": cfg.claude_api_key,
        "Content-Type": "application/json",
        "anthropic-version": "2023-06-01"
    }
    data = {
        "model": cfg.claude_model,
        "max_tokens": 500,
        "messages": [{"role": "user", "content": text_prompt}]
    }
    response = requests.post(url, headers=headers, json=data)
    response.raise_for_status()
    return response.json()["content"][0]["text"]



def generate_text_with_chatgpt(text_prompt):
    if cfg.demo:
        log.warning("This is a Demo only. Switch off the Demo Flag in config.ini to get rid of this")
        return "This is a Demo only. Switch off the Demo Flag in config.ini to get rid of this"

    log.info("Generate content with ChatGPT...")

    log.debug(f"Prompt for Text:  {text_prompt}")
    response = openai_client.chat.completions.create(
        model=cfg.openai_text_model,  # aktuelles ChatGPT-Modell
        messages=[
            {"role": "system", "content":cfg.system_prompt},
            {"role": "user", "content": text_prompt}
        ],
        #max_tokens=500,
        #temperature=0.7
    )

    # Text aus der Antwort extrahieren
    return response.choices[0].message.content.strip()




# --- ChatGPT Pr端fung ---
def check_text_with_chatgpt(text):
    log.info("Check text with ChatGPT.")
    if cfg.demo: return True

    resp = openai_client.chat.completions.create(
        model=cfg.openai_text_model,
        messages=[
            {"role": "system", "content": cfg.check_prompt},
            {"role": "user", "content": text}
        ]
    )
    res = resp.choices[0].message.content.strip()
    log.info(f"Result of the useability check: {res}")
    if res.lower() == "ok":
        return True
    else: return False

    


def generate_image(text):
    if cfg.demo:
        log.warning(f"Demo-Mode is {cfg.demo}")
        imagefile = "https://picsum.photos/200/300"
        return imagefile

    try:
        filename = f"post_{timestamp}.png"
        path = f"{os.getcwd()}/content/images/"
        imagefile = f"{path}{filename}"
        #imagefile = f"/content/images/post_{timestamp}.png"
        log.info(f"Create related Image: {imagefile}")
        
        prompt = f"{cfg.image_prompt} {text}"

        response = openai_client.images.generate(
            model=cfg.openai_image_model,
            prompt = prompt,
            background="opaque",
            output_format = "png",
            moderation="auto",  #auto or low
            quality= "medium",     #low, medium, high or not given
            n = 1,
        )
        
        log.info(f"Cost for this image in Token: Prompt tokens:, {response.usage.input_tokens_details.text_tokens} , Input images tokens: {response.usage.input_tokens_details.image_tokens} , Output image tokens: {response.usage.output_tokens}")

        try:
            log.debug(f"Prompt used for Image generation {prompt}")
            image_bytes = base64.b64decode(response.data[0].b64_json)
            with open(imagefile, "wb") as f:
                f.write(image_bytes)
        except Exception as e:
            log.error(f"Cannot save image due to an Error: \n {e}")

        log.debug("Image generated.")
    except Exception as e:
        log.error(f"No Image generated by AI - returning Demo Image \n {e}")
    finally:
        return filename





# --- HTML-Post speichern ---
def save_post_as_html(text, image, file_path=None):
    if not file_path:   
        file_path=Path(f"{os.getcwd()}/content/new/post_{timestamp}.html")

    render_linkedin_preview(
        template_path=Path(f"{os.getcwd()}/content/templates/{cfg.linkedin_tpl}"),
        out_path=file_path,
        company_name=cfg.company_name,
        logo_url="https://media.licdn.com/dms/image/v2/D4E0BAQFItEUyPgxpAQ/company-logo_100_100/company-logo_100_100/0/1730797026509?e=1759968000&v=beta&t=CFhnhW0YAvXmRjxKGtBTe5XsFWSnvMAzK3mFevmu_hA",
        tagline=cfg.company_tagline,
        text=text,
        image_url=image,
        hashtags="",
        reactions=random.randint(20,500), comments=random.randint(1,50), shares=random.randint(0,10),
        confirmed="False", 
        origin=cfg.post_as
    )
    log.info(f"html preview created as {file_path}")
    return file_path




def move_to_used(src):
    # move from new to used in ../content
    log.debug(f"move to used File: {src}")
    #os.rename(src, dest)
    return True




def move_to_archive(src):
    # move from new to used in ../content
    log.debug(f"move File to archive: {src}")
    file = os.path.basename(src)
    dest = Path(f"{os.getcwd()}/content/archive/{file}")
    os.rename(src, dest)
    log.info(f"{file} moved to archive")
    return True




# Only for CLI Mode
def list_existing_posts():
    files = list(cfg.output_dir.glob("post_*.html"))
    for i, f in enumerate(files):
        print(f"[{i}] {f.name}")
    return files





def render_linkedin_preview(template_path: str, out_path: str, *,
                            company_name: str, logo_url: str, tagline: str,
                            text: str, image_url: str, hashtags: str = "",
                            reactions, comments, shares, confirmed, origin,
                            timestamp=None):
    """F端llt das LinkedIn-Template mit Inhalten und speichert es als HTML."""
    log.debug(f"rendering new html from {template_path}")
    try:
        html = Path(template_path).read_text(encoding="utf-8")
        timestamp = timestamp or datetime.now().strftime("%d.%m.%Y %H:%M")

        title, body = split_post_text(text)

        replacements = {
            "{{TITLE}}": title,
            "{{COMPANY_NAME}}": company_name,
            "{{COMPANY_LOGO_URL}}": logo_url or "",
            "{{COMPANY_TAGLINE}}": tagline or "Unternehmensbeitrag",
            "{{TIMESTAMP}}": timestamp,
            "{{POST_TEXT}}": text,
            "{{POST_IMAGE_URL}}": image_url or "",
            "{{POST_HASHTAGS}}": hashtags or "",
            "{{REACTIONS_COUNT}}": str(reactions),
            "{{COMMENTS_COUNT}}": str(comments),
            "{{SHARES_COUNT}}": str(shares),
            "{{CONFIRMED}}": confirmed or "No",
            "{{ORIGIN}}": origin or "Company",
        }

        for placeholder, value in replacements.items():
            html = html.replace(placeholder, value)

        Path(out_path).parent.mkdir(parents=True, exist_ok=True)
        Path(out_path).write_text(html, encoding="utf-8")
        return out_path
    except Exception as e:
        log.error(f"rendering failed {e}")




def extract_post_elements(html_path: str) -> dict:
    """Liest die Post-Elemente aus einer gespeicherten HTML-Vorschau zur端ck."""
    soup = BeautifulSoup(Path(html_path).read_text(encoding="utf-8"), "html.parser")

    return {
        "company_name": soup.select_one(".company-name").get_text(strip=True),
        "logo_url": soup.select_one(".company-logo")["src"],
        "tagline": soup.select_one(".company-tagline").get_text(strip=True),
        "timestamp": soup.select_one(".timestamp").get_text(strip=True),
        "text": soup.select_one(".post-text").get_text("\n", strip=True),
        "image_url": soup.select_one(".post-image")["src"] if soup.select_one(".post-image") else "",
        "hashtags": soup.select_one(".hashtags").get_text(" ", strip=True),
        "reactions": int(soup.select_one(".reactions").get_text(strip=True).split()[0]),
        "comments": int(soup.select_one(".comments").get_text(strip=True).split()[0]),
        "shares": int(soup.select_one(".shares").get_text(strip=True).split()[0]),
        "confirmed": int(soup.select_one(".confirmed").get_text(strip=True).split()[0]),
    }




def split_post_text(full_text: str):
    """Splits the post text into title (first line) and body (rest)."""
    lines = full_text.strip().split("\n", 1)
    title = lines[0]
    body = lines[1] if len(lines) > 1 else ""
    return title, body




def get_schedules_from_post(filepath):
    """
    Liest alle gespeicherten Schedules aus einer HTML-Datei
    und gibt eine Liste von Dicts zur端ck.
    """
    
    if not os.path.exists(filepath):
        return []

    with open(filepath, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f, "html.parser")

    schedules = []
    for span in soup.select("section.posting-meta span.schedule"):
        dt_raw = span.get("data-datetime")
        repeat_val = span.get("data-repeat", "")

        dt_fmt = dt_raw
        try:
            # Versuchen in lesbares Format umzuwandeln
            dt_obj = datetime.strptime(dt_raw, "%Y-%m-%dT%H:%M")
            dt_fmt = dt_obj.strftime("%d.%m.%Y %H:%M")
        except Exception:
            pass  # wenn Format nicht passt, Rohwert beibehalten

        schedules.append({
            "datetime": dt_raw,
            "datetime_fmt": dt_fmt,
            "repeat": repeat_val
        })

    return schedules



def edit_prompt(old_text: str, new_text: str):
    """
    Edit the Prompts in the promptsfile (from config.ini -> PROMPTS -> text_file)
    Params: existing prompt or empty for a new prompt, new or edited prompt 
    """

    if not os.path.exists(cfg.promptpath):
        open(cfg.promptpath, "w", encoding="utf-8").close()

    with open(cfg.promptpath, "r", encoding="utf-8") as f:
        lines = [line.strip() for line in f.readlines()]

    if old_text:
        updated = False
        for i, line in enumerate(lines):
            if line == old_text.strip():
                lines[i] = new_text.strip()
                updated = True
                break
        if not updated:
            lines.append(new_text.strip())
    else:
        lines.append(new_text.strip())

    with open(cfg.promptpath, "w", encoding="utf-8") as f:
        for line in lines:
            f.write(line + "\n")

    return True